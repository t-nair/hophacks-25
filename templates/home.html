<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mood Journal</title>

</head>
<body>

  <!-- Landing Section -->
  <section id="landing">
    <h1>How do you feel today?</h1>
    <button onclick="document.getElementById('record').scrollIntoView({behavior:'smooth'})">
      REFLECT ON IT!
    </button>
  </section>

  <!-- Recording Section -->
  <section id="record">
    <h1>Record your reflection</h1>
    <video id="preview" autoplay muted></video><br>
    <button id="startRecord">Start Recording</button>
    <button id="stopRecord" style="display:none;">Stop Recording</button>
  </section>

  <!-- Dashboard Section -->
  <section id="dashboard">
    <h2>Your Journal</h2>
    <div class="journal" id="journalText">
      {% if journal_text %}
        <div class="journal-text"></div>
          <h2>Journal Entry Text:</h2>
          <p>{{ journal_text }}</p>
        </div>
      {% else %}
        <p>Processing your reflection...</p>
      {% endif %}
    </div>
    <canvas id="moodChart"></canvas>
  </section>

  <!-- Chart.js -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

  <script>
    const video = document.getElementById('preview');
    const startBtn = document.getElementById('startRecord');
    const stopBtn = document.getElementById('stopRecord');
    const dashboard = document.getElementById('dashboard');
    const journalDiv = document.getElementById('journalText');
    const recordSection = document.getElementById('record');

    let mediaRecorder;
    let chunks = [];

    // Request camera & mic access
    navigator.mediaDevices.getUserMedia({ video: true, audio: true })
      .then(stream => {
        video.srcObject = stream;
        mediaRecorder = new MediaRecorder(stream);

        mediaRecorder.ondataavailable = e => chunks.push(e.data);

        mediaRecorder.onstop = async () => {
          const blob = new Blob(chunks, { type: 'video/webm' });
          const formData = new FormData();
          formData.append('video', blob, 'journal.webm');

          // Upload to Flask
          const response = await fetch('/upload', {
            method: 'POST',
            body: formData
          });
          const data = await response.text();

          // Show dashboard
          recordSection.style.display = "none";
          dashboard.style.display = "flex";
          journalDiv.innerHTML = data;

          // Chart (example, static numbers for now)
          new Chart(document.getElementById('moodChart'), {
            type: 'radar',
            data: {
              labels: ['Happy', 'Calm', 'Focused', 'Stressed', 'Excited'],
              datasets: [{
                label: 'Your Mood',
                data: [65, 80, 70, 40, 90],
                backgroundColor: 'rgba(54,162,235,0.2)',
                borderColor: 'rgba(54,162,235,1)',
                borderWidth: 2
              }]
            }
          });
        };
      });

    // Start 5s recording
    startBtn.onclick = () => {
    chunks = [];
    mediaRecorder.start();
    startBtn.textContent = "Recording...";
    stopBtn.style.display = "inline-block"; // ✅ show stop button
    };

// Stop recording
  stopBtn.onclick = () => {
    mediaRecorder.stop();
    startBtn.textContent = "Start Recording";
    stopBtn.style.display = "none"; // ✅ hide stop button again
  };

  </script>
</body>
</html>
